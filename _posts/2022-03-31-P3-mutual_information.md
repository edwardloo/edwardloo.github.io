---
title: "Mutual Information"
---

---
Definitions:

> "The mutual information (MI) of 2 random variables is a measure of the mutual dependence between 2 variables." - Wikipedia

> "The Mutual Information between 2 random variables is the amount of information that one gains about a random variable by observing the value of the other." - Layman's term

# Comparison with Correlation Coefficient

| MI | Correlation |
|----|-------------|


---
References
1. [Mutual Information](https://en.wikipedia.org/wiki/Mutual_information)
2. [Correlation and Mutual Information](https://eng.libretexts.org/Bookshelves/Industrial_and_Systems_Engineering/Book%3A_Chemical_Process_Dynamics_and_Controls_(Woolf)/13%3A_Statistics_and_Probability_Background/13.13%3A_Correlation_and_Mutual_Information#:~:text=Correlation%20analysis%20provides%20a%20quantitative,the%20value%20of%20another%20variable.)
3. [Correlation vs Mutual Information](http://www.mathemafrica.org/?p=16127)
